{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nikit\\anaconda3\\lib\\site-packages (from bs4) (4.6.3)\n",
      "Building wheels for collected packages: bs4\n",
      "  Running setup.py bdist_wheel for bs4: started\n",
      "  Running setup.py bdist_wheel for bs4: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\nikit\\AppData\\Local\\pip\\Cache\\wheels\\a0\\b0\\b2\\4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://www.foxsports.com/nhl/team-stats?season=2017&category=SPECIAL+TEAMS' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    print(soup.find('div', class_='wisbb_statsTable').find_all('td')[0+14].text)\n",
    "    print(soup.find('div', class_='wisbb_statsTable').find_all('td')[3+14].text)\n",
    "    print(soup.find('div', class_='wisbb_statsTable').find_all('td')[4+14].text)\n",
    "    print(soup.find('div', class_='wisbb_statsTable').find_all('td')[6+14].text)\n",
    "    print(soup.find('div', class_='wisbb_statsTable').find_all('td')[7+14].text)\n",
    "    print(soup.find('div', class_='wisbb_statsTable').find_all('td')[9+14].text)\n",
    "    print(soup.find('div', class_='wisbb_statsTable').find_all('td')[10+14].text)\n",
    "    print(soup.find('div', class_='wisbb_statsTable').find_all('td')[12+14].text)\n",
    "    print(soup.find('div', class_='wisbb_statsTable').find_all('td')[13+14].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\\n\\n1\\n\\nPittsburgh\\nPIT\\n\\n', '260', '26.2%', '265', '2.3%', '265', '80.0%', '260', '98.8%'], ['\\n\\n2\\n\\nTampa Bay\\nTB\\n\\n', '276', '23.9%', '268', '3.4%', '268', '76.1%', '276', '98.9%'], ['\\n\\n3\\n\\nColorado\\nCOL\\n\\n', '296', '22.0%', '269', '2.6%', '269', '83.3%', '296', '95.6%'], ['\\n\\n4\\n\\nWinnipeg\\nWPG\\n\\n', '274', '23.4%', '274', '3.3%', '274', '81.8%', '274', '97.4%'], ['\\n\\n5\\n\\nBoston\\nBOS\\n\\n', '259', '23.6%', '245', '3.7%', '245', '83.7%', '259', '96.1%'], ['\\n\\n6\\n\\nNew York\\nNYI\\n\\n', '250', '23.2%', '235', '2.1%', '235', '73.2%', '250', '95.6%'], ['\\n\\n6\\n\\nNashville\\nNSH\\n\\n', '273', '21.2%', '299', '3.3%', '299', '81.9%', '273', '98.2%'], ['\\n\\n8\\n\\nToronto\\nTOR\\n\\n', '224', '25.0%', '231', '1.7%', '231', '81.4%', '224', '97.8%'], ['\\n\\n9\\n\\nWashington\\nWSH\\n\\n', '244', '22.5%', '269', '1.5%', '269', '80.3%', '244', '96.7%'], ['\\n\\n10\\n\\nNew Jersey\\nNJ\\n\\n', '252', '21.4%', '258', '4.7%', '258', '81.8%', '252', '97.6%'], ['\\n\\n10\\n\\nPhiladelphia\\nPHI\\n\\n', '261', '20.7%', '223', '1.3%', '223', '75.8%', '261', '96.2%'], ['\\n\\n12\\n\\nSan Jose\\nSJ\\n\\n', '257', '20.6%', '224', '3.6%', '224', '84.8%', '257', '98.8%'], ['\\n\\n12\\n\\nVancouver\\nVAN\\n\\n', '247', '21.5%', '276', '2.5%', '276', '78.3%', '247', '96.0%'], ['\\n\\n12\\n\\nVegas\\nVGK\\n\\n', '248', '21.4%', '237', '3.4%', '237', '81.4%', '248', '98.0%'], ['\\n\\n15\\n\\nMontreal\\nMTL\\n\\n', '245', '21.2%', '263', '2.7%', '263', '74.1%', '245', '97.6%'], ['\\n\\n16\\n\\nNew York\\nNYR\\n\\n', '241', '21.2%', '247', '2.0%', '247', '81.4%', '241', '97.9%'], ['\\n\\n17\\n\\nBuffalo\\nBUF\\n\\n', '257', '19.1%', '235', '3.8%', '235', '77.9%', '257', '96.1%'], ['\\n\\n17\\n\\nMinnesota\\nMIN\\n\\n', '240', '20.4%', '272', '2.6%', '272', '81.3%', '240', '97.5%'], ['\\n\\n17\\n\\nLos Angeles\\nLA\\n\\n', '240', '20.4%', '260', '1.9%', '260', '85.0%', '240', '98.3%'], ['\\n\\n20\\n\\nFlorida\\nFLA\\n\\n', '249', '18.9%', '227', '4.4%', '227', '80.2%', '249', '98.0%'], ['\\n\\n20\\n\\nDallas\\nDAL\\n\\n', '244', '19.3%', '281', '2.5%', '281', '80.8%', '244', '95.9%'], ['\\n\\n22\\n\\nCarolina\\nCAR\\n\\n', '239', '18.4%', '191', '1.6%', '191', '77.5%', '239', '97.5%'], ['\\n\\n23\\n\\nChicago\\nCHI\\n\\n', '269', '16.0%', '235', '2.1%', '235', '79.1%', '269', '97.4%'], ['\\n\\n23\\n\\nCalgary\\nCGY\\n\\n', '269', '16.0%', '269', '2.6%', '269', '81.8%', '269', '97.4%'], ['\\n\\n25\\n\\nOttawa\\nOTT\\n\\n', '247', '16.6%', '235', '1.7%', '235', '76.2%', '247', '97.6%'], ['\\n\\n25\\n\\nDetroit\\nDET\\n\\n', '234', '17.5%', '258', '3.5%', '258', '77.5%', '234', '97.9%'], ['\\n\\n25\\n\\nArizona\\nARZ\\n\\n', '243', '16.9%', '225', '0.9%', '225', '79.6%', '243', '95.9%'], ['\\n\\n28\\n\\nColumbus\\nCBJ\\n\\n', '227', '17.2%', '214', '1.9%', '214', '76.2%', '227', '96.9%'], ['\\n\\n29\\n\\nSt. Louis\\nSTL\\n\\n', '246', '15.4%', '231', '2.2%', '231', '79.7%', '246', '96.3%'], ['\\n\\n29\\n\\nAnaheim\\nANA\\n\\n', '214', '17.8%', '274', '3.6%', '274', '83.2%', '214', '98.1%'], ['\\n\\n31\\n\\nEdmonton\\nEDM\\n\\n', '210', '14.8%', '245', '4.5%', '245', '76.7%', '210', '97.6%']]\n"
     ]
    }
   ],
   "source": [
    "parse(get_html(BASE_URL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_writer(data, path):\n",
    "    \"\"\"\n",
    "    Write data to a CSV file path\n",
    "    \"\"\"\n",
    "    with open(path, \"w\", newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        for line in data:\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    data = []\n",
    "    teamData = []\n",
    "    it = 0\n",
    "    for i in range(31):\n",
    "        teamData = []\n",
    "        teamData.append(soup.find('div', class_='wisbb_statsTable').find_all('td')[0+it].text)\n",
    "        teamData.append(soup.find('div', class_='wisbb_statsTable').find_all('td')[3+it].text)\n",
    "        teamData.append(soup.find('div', class_='wisbb_statsTable').find_all('td')[4+it].text)\n",
    "        teamData.append(soup.find('div', class_='wisbb_statsTable').find_all('td')[6+it].text)\n",
    "        teamData.append(soup.find('div', class_='wisbb_statsTable').find_all('td')[7+it].text)\n",
    "        teamData.append(soup.find('div', class_='wisbb_statsTable').find_all('td')[9+it].text)\n",
    "        teamData.append(soup.find('div', class_='wisbb_statsTable').find_all('td')[10+it].text)\n",
    "        teamData.append(soup.find('div', class_='wisbb_statsTable').find_all('td')[12+it].text)\n",
    "        teamData.append(soup.find('div', class_='wisbb_statsTable').find_all('td')[13+it].text)\n",
    "        data.append(teamData)\n",
    "        it+=14\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = [\"first_name,last_name,city\".split(\",\"),\n",
    "            \"Tyrese,Hirthe,Strackeport\".split(\",\"),\n",
    "            \"Jules,Dicki,Lake Nickolasville\".split(\",\"),\n",
    "            \"Dedric,Medhurst,Stiedemannberg\".split(\",\")\n",
    "            ]\n",
    "    \n",
    "    path = \"df.csv\"\n",
    "    csv_writer(data, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
